---
title: "MIDTERNONWARD"
output: html_document
---

R times Web Scraper

```{r, eval=FALSE}
Sys.setenv(NYTIMES_AS_KEY = "b4969dfbe67548568bf022335e4bd5fb")
  
bit <- as_search(q="bitcoin", begin_date = "20100101", end_date = '20180401', all_results = TRUE)  

crypt <- as_search(q="cryptocurrency", begin_date = "20100101", end_date = '20180401', all_results = TRUE)  
```

bitcoin yields more data points (1154 to cryto's 125)

want to use sentiment analysis to rate headlines

bring in tm_cleaner function

```{r}
tm_cleaner <- function(corpus, stop=stopwords("en"), rm_num=TRUE) {
  require(tm)
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, stop)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(function(x) gsub("http\\w+", "", x)))
  return(corpus)
}

```

created function to generate dataframes of sentiment analysis with diffrent dictionarys
where 
"dataNYT" is a dataframe generated from rtimes. 

```{r, eval=FALSE}
sentimentoutput <- function(dataNYT)  {
  
library(rvest)
library(SentimentAnalysis)
library(stringr)
library(dplyr)
library(tm)

data <-  dataNYT$data   
  
headlines <- data$headline.main

headlinecorpus <- Corpus(VectorSource(headlines))

headlineclean <- tm_cleaner(headlinecorpus)

sentimentnum <- analyzeSentiment(headlineclean)

GI <-convertToBinaryResponse(sentimentnum$SentimentGI)
LM <-convertToBinaryResponse(sentimentnum$SentimentLM)
QDAP <-convertToBinaryResponse(sentimentnum$SentimentQDAP)

headlineoriginal <- factor(data$headline.main)

GI_num <- ifelse(GI =="positive",1,-1) 
LM_num <- ifelse(LM =="positive",1,-1) 
QDAP_num <- ifelse(QDAP =="positive",1,-1) 

analysis <- data.frame(Score=factor(GI_num + LM_num + QDAP_num),
  GI=factor(GI),
  LM=factor(LM),
  QDAP=factor(QDAP),
  Headline=factor(data$headline.main),
  date=as.Date(data$pub_date),
  stringsAsFactors=FALSE)

return(analysis)

}

```

Have a score in this set, to factor in responses from all dictionaries 


```{r , eval=FALSE}
bitdata <- sentimentoutput(bit)

cryptdata <- sentimentoutput(crypt)

```

Looking at the data, there are a number of headlines that dont seem to have much to do with bitcoin or crypto currency. will delete rows if no string of bitcoin and cryptocurrency exist

```{r , eval=FALSE}

library(stringr)
library(dplyr)
cleanbit <- bitdata %>%
  filter(str_detect(Headline, "Bitcoin"))

cleancrypt <- cryptdata %>%
  filter(str_detect(Headline, "Cryptocurrencies"))
```

will graph this data see what we find

```{r , eval=FALSE}
library(ggplot2)
ggplot(cleanbit) + 
  geom_point(aes(x=date, y=Score)) 

```

There appears to be a high amount of "good" headlines concerning bitcoin (scores of three). This seems to be promising coorelating with the increse in market vaule, but I would like to create some kind of density graph so we can see where media coverage was at its highest.

```{r , eval=FALSE}
library(dplyr)
table <- cleanbit %>%
  group_by(date) %>%
  summarise (n = n())
```

```{r , eval=FALSE}
ggplot(table) + geom_density(aes(date))
```

it seems NYT intrest peaked around early 2014. 

plotting bitcoin again

```{r , eval=FALSE}
alldata$date <- as.Date(alldata$date,"%m/%d/%Y")

ggplot(subset(alldata,slug %in% c("bitcoin"))) + 
  geom_line(aes(x=date, y=close)) 

```

function to create news frequency table

```{r}
freqnews <- function(analyze, word) {
library(stringr)
library(dplyr)
clean <- analyze %>%
  filter(str_detect(Headline, word))

table <- clean %>%
  group_by(date) %>%
  summarise (n = n())


return(table)

}
```

```{r, eval=FALSE}
table <- freqnews(bitdata,"Bitcoin")


ggplot(table) + 
  geom_line(aes(x=date, y=n)) 
```


let me create a function that i can drop any rtimes file into to rate and aggregate 

"analyze" is a dataset generated from previous "sentiment output"" function
"word" is a chracter string that if a row doesnt not contain, it is deleted

```{r}
aggregatescore <- function(analyze,word) {
library(stringr)
library(dplyr)
clean <- analyze %>%
  filter(str_detect(Headline, word))

table <- clean %>%
  group_by(date) %>%
  summarise (n = n())


clean$Score <- as.numeric(as.character(clean$Score))

sums <- clean %>%
           group_by(date) %>%
           summarise(sum = sum(Score))

return(sums)  
  
}


```

```{r, eval=FALSE}
cleanbitagg <- aggregatescore(bitdata,"Bitcoin")

```

When we plot with a dataset cleaned for the chracter string bitcoin in the headlines we find that most coverage is postive when we add the score for each date. 


```{r, eval=FALSE}
library(ggplot2)
ggplot(cleanbitagg) + geom_point(aes(x=date,y=sum, colour = sum <0)) +
  scale_colour_manual(name = 'Sum < 0', values = setNames(c('red','green'),c(T, F))) +
  xlab('date') + ylab('score of date')
```

let me pull the dates of that have a score larger than 5, and see what they have in common

```{r}

topheadline <- function(analyze,word, condition) {
library(stringr)
library(dplyr)
clean <- analyze %>%
  filter(str_detect(Headline, word))

table <- clean %>%
  group_by(date) %>%
  summarise (n = n())


clean$Score <- as.numeric(as.character(clean$Score))

sums <- clean %>%
           group_by(date) %>%
           summarise(sum = sum(Score))

  
dates <- subset(sums, eval(parse(text=condition)), 
select=c(date))  

complete <- merge(dates,clean,by = "date")

return(complete)

}

```

```{r, eval=FALSE}
topheadline<- topheadline(bitdata,"Bitcoin","sum > 0")
```

When using the above function to isolate headlines form days with a high news score I find reundent headlines. This can affect the score and make my results less meaningful. Will creat function to eleminate duplicates and hopefully near duplicates. 


I will modify my sentimentoutput function 

```{r}
sentimentoutput <- function(dataNYT)  {
  
library(rvest)
library(SentimentAnalysis)
library(stringr)
library(dplyr)
library(tm)

data <-  dataNYT$data   

headlines <- data$headline.main

headlinecorpus <- Corpus(VectorSource(headlines))

headlineclean <- tm_cleaner(headlinecorpus)

sentimentnum <- analyzeSentiment(headlineclean)

GI <-convertToBinaryResponse(sentimentnum$SentimentGI)
LM <-convertToBinaryResponse(sentimentnum$SentimentLM)
QDAP <-convertToBinaryResponse(sentimentnum$SentimentQDAP)

headlineoriginal <- factor(data$headline.main)

GI_num <- ifelse(GI =="positive",1,-1) 
LM_num <- ifelse(LM =="positive",1,-1) 
QDAP_num <- ifelse(QDAP =="positive",1,-1) 

analysis <- data.frame(Score=factor(GI_num + LM_num + QDAP_num),
  GI=factor(GI),
  LM=factor(LM),
  QDAP=factor(QDAP),
  Headline=factor(data$headline.main),
  date=as.Date(data$pub_date),
  stringsAsFactors=FALSE)

analysis2 <- unique(analysis)

return(analysis2)

}
```
test 

```{r, eval=FALSE}
bitdata <- sentimentoutput(bit)
```

1154 to 1145, the outliers may have been just duplicates.


Let me summerize work flow at this point

1. genreate dataset from rtimes

2. drop dataset into "sentimentoutput" function to rate each headline. Generates table with score,GI,LM,QDAP rating,headline,date. Score is an aggregate sum where each rating is either 1=postive or -1 negative.  

Sentimentoutput <- function(dataNYT)

dataNYT-dataset genreated from scrapping with rtimes package

--------------------------------------------
From there we can use the following functions: freqnews,aggregatescore, or topheadline.
---------------------------------------------

aggregatescore - genreates table with date and score. Score is sum of headline news scores. 

aggregatescore <- function(analyze,word)

analyze-dataset generated from sentimentoutput

word-chracter string filter (i.e. "bitcoin")

---------------------------------------------

freqnews - generates table with date and number of headlines.

freqnews <- function(analyze, word)

analyze-dataset generated from sentimentoutput

word-chracter string filter (i.e. "bitcoin")

---------------------------------------------

topheadline - filters table to include headlines from dates with that have a score within a specified range

topheadline <- function(analyze,word, x)

analyze-dataset generated from sentimentoutput

word-chracter string filter (i.e. "bitcoin")

condition-specifed range (i.e. "10 > sum" )


--------------------------------------------

wordc-generates wordcloud, from rtimes dataset 
wordc <- function(analyze,word,condition,y)

analyze-dataset generated from sentimentoutput

word-chracter string filter (i.e. "bitcoin")

condition-specifed range (i.e. "10 > sum" )

y - max words (i.e. 10)

-------------------------------------------
Lets create a word cloud of the top headlines based on the topheadline function.


```{r}
wordc <- function(analyze,word,condition,y) {
library(tm)
library(wordcloud)
library(RColorBrewer)
library(stringr)
library(dplyr)
library(SnowballC)

clean <- analyze %>%
  filter(str_detect(Headline, word))

clean$Score <- as.numeric(as.character(clean$Score))

sums <- clean %>%
           group_by(date) %>%
           summarise(sum = sum(Score))

  
dates <- subset(sums,eval(parse(text=condition)), 
select=c(date))  

complete <- merge(dates,clean,by = "date")

Corpus <- Corpus(VectorSource(complete$Headline))


wordcloud(Corpus, max.words = y, random.order = FALSE)

}

```

```{r}
wordc(bitdata,"Bitcoin","sum > 5",100)
```


```{r}
wordc(bitdata,"Bitcoin", condition="sum > 5",50)
```









