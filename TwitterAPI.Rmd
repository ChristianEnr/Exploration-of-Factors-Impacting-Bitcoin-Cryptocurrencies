---
title: "TwitterAPI"
output: html_document
---



```{r,eval=FALSE}
library(rtweet)


## whatever name you assigned to your created app
appname <- "rtweet_ce"

## api key
key <- "gaZ7oOlxa5M7e0ndqQRX4ZCXy"

## api secret 
secret <- "0gBA23qT2ZgW2rUHRCwcObH8ScjeC9uAugH2eQS7r8o6EodD6r"

## create token named "twitter_token"
twitter_token <- create_token(
  app = appname,
  consumer_key = key,
  consumer_secret = secret)


```


Tweets from Coindesk.com

```{r,eval=FALSE}
coindesk <- get_timelines(c("coindesk"), n = 3200)
```


Tweets from Cointelegraph.com

```{r,eval=FALSE}
cointelegraph <- get_timelines(c("Cointelegraph"), n = 3200, include_rts=FALSE)
```

Tweets from Bitcoin Magazine (threw out)

```{r,eval=FALSE}
BitcoinMagazine <- get_timelines(c("BitcoinMagazine"), n = 3200,include_rts=FALSE)
```

Tweets from The Merkle
```{r,eval=FALSE}
TheMerkle <- get_timelines(c("themerklenews"), n = 3200,include_rts=FALSE)
```

Tweets from CCN

```{r,eval=FALSE}
CCN <- get_timelines(c("CryptoCoinsNews"), n = 3200,include_rts=FALSE)
```

Tweets from Bitcoin News

```{r,eval=FALSE}
BitcoinNews <- get_timelines(c("BTCTN"), n = 3200,include_rts=FALSE)
```






```{r}
tm_cleaner <- function(corpus, stop=stopwords("en"), rm_num=TRUE) {
  # Cleans a corpus object of spaces,numbers,case,stop words, and punctuation
  # Args:
  # Corpus: Object to be cleaned
  # stop=stopwords(""): define dictionary from which corrsponding stopwords will be pulled
  # rm_num: True or False argument
  #
  #Returns: 
  #Cleaned corpus object where number of rows is equal to input cprpus object.
  #
  require(tm)
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, stop)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(function(x) gsub("http\\w+", "", x)))
  return(corpus)
}
```



```{r}
sentimentoutputconttweet <- function(data)  {
#Generates data frame of tweet and continous sentiment analysis results (positive/negative) from the following dictionaries: General Inquirer(Harvard-IV), Loughran-McDonald financial dictionary, and QDAP (polarity words from qdap package).   

#Also adds a variable called "score" where the results of the Sentiment dictionary vaules are added together to form an aggregate score. 
  
#Returns unique text  
#  
#Arg:
#data- dataframe genreated from scrapping with rtimes package 

#Return
#analysis- dataframe with Score(Factor),GI(Factor),LM(Factor),QDAP(Factor),Headline(Factor),Date(Date),Variance   
  
library(rvest)
library(SentimentAnalysis)
library(stringr)
library(dplyr)
library(tm)
library(textclean)

test <- replace_non_ascii(data$text, remove.nonconverted = TRUE)  
  
tweets <- test

tweetcorpus <- Corpus(VectorSource(tweets))

tweetclean <- tm_cleaner(tweetcorpus)

sentimentnum <- analyzeSentiment(tweetclean)

GI <-(sentimentnum$SentimentGI)
LM <-(sentimentnum$SentimentLM)
QDAP <-(sentimentnum$SentimentQDAP)

tweetoriginal <- factor(data$text)

Score <- (GI + LM + QDAP)

var <- 0.5* ((((GI)-(Score/3))^2) + (((LM)-(Score/3))^2) + (((QDAP)-(Score/3))^2))

analysis <- data.frame(Score=as.numeric(GI + LM + QDAP),
  GI=as.numeric(GI),
  LM=as.numeric(LM),
  QDAP=as.numeric(QDAP),
  Headline=factor(data$text),
  date=as.Date(data$created_at),
  Var=as.numeric(var),
  stringsAsFactors=FALSE)

analysis <- analysis[complete.cases(analysis), ]

analysis2 <- unique(analysis)

return(analysis2) 

}
```


```{r}
coindeskdata <- sentimentoutputconttweet(coindesk)
firsttweetplot(coindeskdata,"Coindesk")
```


```{r}
BitcoinNewsData <- sentimentoutputconttweet(BitcoinNews)
firsttweetplot(BitcoinNewsData,"BitcoinNews")
```


```{r}
cointelegraphdata <- sentimentoutputconttweet(cointelegraph)
firsttweetplot(cointelegraphdata,"Cointelegraph")
```


```{r}
BitcoinMagazinedata <- sentimentoutputconttweet(BitcoinMagazine)
firsttweetplot(BitcoinMagazinedata,"BitcoinMagazine")
```


```{r}
TheMerkledata <- sentimentoutputconttweet(TheMerkle)
firsttweetplot(TheMerkledata,"TheMerkle")
```


```{r}
CCNdata <- sentimentoutputconttweet(CCN)
firsttweetplot(CCNdata,"CCN")
```


```{r}
firsttweetplot <-function (data,title){
library(plotly)
library(ggplot2)
ggplot(data) + geom_point(aes(x=date,y=Score, colour = Score <0)) +
  scale_colour_manual(name = 'Score < 0', values = setNames(c('red','green'),c(T, F))) +
  xlab('date') + ylab('score of date') + ggtitle(title, subtitle = ("Score"))  
  
}
```


```{r}
alltweets   <-   rbind(CCNdata,TheMerkledata)
alltweets   <-   rbind(alltweets,BitcoinNewsData)
alltweets   <-   rbind(alltweets,cointelegraphdata)
alltweets   <-   rbind(alltweets,coindeskdata)
```


```{r}
firsttweetplot(alltweets,"alltweets")
```


```{r}
aggregatescoretweet <- function(data) {
#Function to aggregate the scores of all tweets from a particular date into one aggregate score per date
  
#Args:  
#analyze -  dataframe with Score,GI,LM,QDAP,Headline,Date [Output from Previously Defined SentimentAnalysis function]
#Word - Character string to filter headlines by   
#Returns:  
#sums - dataframe with Date and Corresponding Aggregate Score (sum).  
    
library(stringr)
library(dplyr)

sums <- data %>%
           group_by(date) %>%
           summarise(Score = sum(Score))

return(sums)  
  
}

```


```{r}
test <- aggregatescoretweet(alltweets)
```

```{r}
firsttweetplot(test,test)
```

```{r}
aggregatescoreproper <- function(data) {

    
library(stringr)
library(dplyr)


table <- data %>%
  group_by(date) %>%
  summarise (n = n())


sums <- data %>%
           group_by(date) %>%
           summarise(Score = sum(Score)) 

result <- data.frame(date=as.Date(table$date),
                     Score=as.numeric((sums$Score)/(table$n)))
                     
                     


return(result)  
  
}

```

```{r}
alltweetsaggscoreavg <- aggregatescoreproper(alltweets)
```


```{r}
firsttweetplot(alltweetsaggscoreavg,"Average Score Per Day") 
```

```{r}
ggplot(alltweetsaggscoreavg,aes(x=date,y=Score)) + geom_point() + 
  xlab('date') + ylab('score of date') + ggtitle("title", subtitle = ("Score")) + geom_smooth() 
```



Cluster

```{r}
market_price$`date` <- as.Date(market_price$`2017-05-01 00:00:00`)
```

```{r}
 bitcoinpricesubset <- subset(market_price, date > "2017-09-06" & date < "2018-05-02")
```

```{r}
tweetscoresubset <- subset(alltweetsaggscoreavg, date < "2018-05-01")
```


```{r}
cluster <- merge(bitcoinpricesubset,tweetscoresubset, by= "date")

cluster$`2017-05-01 00:00:00` <- NULL
cluster$date <- NULL
cluster$Bitcoin <- cluster$`1417.1728125`
cluster$`1417.1728125` <- NULL
```



```{r}
ggplot(cluster) + 
  geom_point(aes(x = Score, y =Bitcoin))
```


```{r}
ggplot(cluster, aes(Date)) + 
  geom_line(aes(y = Score, colour = "Score")) + 
  geom_line(aes(y = Bitcoin/100000, colour = "Bitcoin"))
```

```{r}
t.test(cluster$Bitcoin,cluster$Score)
```




```{r}
library(plotly)

p <- firsttweetplot(alltweetsaggscoreavg,"Average Score Per Day")
p <- ggplotly(p)

```




